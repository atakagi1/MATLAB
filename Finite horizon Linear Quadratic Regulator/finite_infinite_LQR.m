clear variables; close all; clc;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This program simulates an optimal controller (finite horizon linear
% quadratic regulator [LQR]) reaching a position in one dimension.
% It also simulates an infinite horizon LQR reaching to the same target.
%
% Neuroscientists may notice that the force generated by each controller and the
% simulated trajectories are different. This is because the finite horizon
% LQR has time-dependent gains while the infinite horizon LQR has a
% constant gain. The bell-shaped velocity profile is observed only with the
% finite horizon LQR.
% ----------------------
% Feel free to edit this code and use as you wish!
%
% Atsushi Takagi (2021/03/05) - written and tested in MATLAB 2018b
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Time step size (in seconds)
dt = 0.001;
% Create a time vector (determining length of simulation)
Time = 0:dt:1;
% Mass of controlled entity in kg
m = 1;
% Position and velocity of target to reach (in m and m/s)
Target = [1; 0];

% State control cost matrix (first dimension punishes deviation from target
% position, second dimension punishes deviation from target velocity)
Q = [1,0   ; 
     0,0.1];
% Control cost matrix
R = 0.000001;

% The dynamics simulated in this code in discrete time is:
%       x = x+v*dt
%       v = u
% where
%   x - position
%   v - velocity
%   u - force (commonly referred to as control command)

% State transition matrix
A = [1,dt;
     0,1 ];
% Control input matrix
B = [0; 
     dt/m];

% Allocation of memory
x = zeros(size(A,1),length(Time));
u = zeros(size(B,2),length(Time)-1);
xDLQR = x; uDLQR = u;

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Derive the control gains for finite-horizon LQR

% Set the last cost to be the state cost
P(:,:,length(Time)) = Q;
for i=length(Time)-1:-1:1 % note this is going backward in time
    % Backwards pass of the discrete Ricatti equation until the beginning
    P(:,:,i) = A'*P(:,:,i+1)*A - A'*P(:,:,i+1)*B/(R+B'*P(:,:,i+1)*B)*B'*P(:,:,i+1)*A;
end
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Derive the control gain for the infinite-horizon LQR

% Define tolerance until cost converges
Tolerance = 0.001;
% Initialize while loop with state cost
P_DLQR = Q;
P_store = 0*P_DLQR;
% Solve discrete Ricatti until convergence within Tolerance value
while sum(sum(abs(P_DLQR-P_store)>ones(length(P_DLQR))*Tolerance))>0
    P_store = P_DLQR;
    P_DLQR = Q+A'*P_DLQR*A-A'*P_DLQR*B/(R+B'*P_DLQR*B)*B'*P_DLQR*A;
end
% Get the constant control gain
L_DLQR = (R+B'*P_DLQR*B)\B'*P_DLQR*A;
% should be comparable to L_DLQR  = dlqr(A,B,Q,R);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Simulate the two systems
for i=1:length(Time)-1
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % SIMULATE FINITE-HORIZON CONTROL
    
    % Calculate the gain for the finite-horizon LQR at specific time instance
    L = -(R+B'*P(:,:,i+1)*B)\B'*P(:,:,i+1)*A;
    % Compute control command to go towards Target (if Target is non-zero, this is referred to as 'setpoint control')
    u(:,i) = L*(x(:,i)-Target);
    % Move the dynamic system forward in time
    x(:,i+1) = A*x(:,i)+B*u(:,i);
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % SIMULATE INFINITE-HORIZON CONTROL
    
    % Calculate control command to reach target
    uDLQR(:,i) = -L_DLQR*(xDLQR(:,i)-Target);
    % Move system forward in time
    xDLQR(:,i+1) = A*xDLQR(:,i)+B*uDLQR(:,i);
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
end

%% PLOTS

% Open a new figure
figure(1); clf(1); set(gcf,'color','w'); hold on;

% Create a new subfigure to show the position profiles of both controllers
subplot(4,1,1); set(gca,'fontsize',15); pbaspect([3,1,1]); hold on;
line([0,Time(end)],[1,1]*Target(1),'color','k','linewidth',1,'linestyle','--');
plot(Time,x(1,:),'b','linewidth',2);
plot(Time,xDLQR(1,:),'r','linewidth',2);
ylabel('pos (m)');
legend('target','finite-horizion LQR','infinite-horizon LQR','location','southeastoutside'); legend boxoff;

% Subfigure showing the velocity profiles
% finite-horizon shows the bell-shaped profile as observed in human
% reaching, while infinite-horizon has a lop-sided curve, which is observed
% in humans reaching precise targets (e.g. threading a needle)
subplot(4,1,2); set(gca,'fontsize',15); pbaspect([3,1,1]); hold on;
plot(Time,x(2,:),'b','linewidth',2);
plot(Time,xDLQR(2,:),'r','linewidth',2);
ylabel('vel (m/s)');

% Subfigures showing the control commands sent by each controller
% notice how the infinite-horizon LQR sends immensely large forces while
% the finite-horizon is more conservative
subplot(4,1,3); set(gca,'fontsize',15); pbaspect([3,1,1]); hold on;
line([0,Time(end)],[0,0],'color','k','linewidth',1);
plot(Time(1:end-1),u(1,:),'b','linewidth',2);
ylabel('u (N)');
subplot(4,1,4); set(gca,'fontsize',15); pbaspect([3,1,1]); hold on;
plot(Time(1:end-1),uDLQR(1,:),'r','linewidth',2);
ylabel('u (N)');
xlabel('Time (s)');
